"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[4744],{87:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"module-4-vla/llm-planner","title":"The LLM Planner","description":"1. Prompt Engineering for Robots","source":"@site/docs/module-4-vla/03-llm-planner.md","sourceDirName":"module-4-vla","slug":"/module-4-vla/llm-planner","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/llm-planner","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-4-vla/03-llm-planner.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"The LLM Planner"},"sidebar":"textbookSidebar","previous":{"title":"Voice Command (Whisper)","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/whisper-integration"},"next":{"title":"Capstone: The Butler Robot","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/capstone-project"}}');var s=t(4848),i=t(8453);const r={sidebar_position:3,title:"The LLM Planner"},l="Cognitive Planning with LLMs",a={},c=[{value:"1. Prompt Engineering for Robots",id:"1-prompt-engineering-for-robots",level:2},{value:"1.1 The System Prompt",id:"11-the-system-prompt",level:3},{value:"2. ReAct: Reason + Act",id:"2-react-reason--act",level:2},{value:"3. Implementing the Planner in Python",id:"3-implementing-the-planner-in-python",level:2},{value:"4. The Capstone: Putting it All Together",id:"4-the-capstone-putting-it-all-together",level:2}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"cognitive-planning-with-llms",children:"Cognitive Planning with LLMs"})}),"\n",(0,s.jsx)(n.h2,{id:"1-prompt-engineering-for-robots",children:"1. Prompt Engineering for Robots"}),"\n",(0,s.jsxs)(n.p,{children:['You cannot just ask ChatGPT "clean the room." You need to give it a ',(0,s.jsx)(n.strong,{children:"Function Interface"})," (Tools)."]}),"\n",(0,s.jsx)(n.h3,{id:"11-the-system-prompt",children:"1.1 The System Prompt"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'You are the brain of a humanoid robot named Cortex-H1.\nYou have access to the following low-level tools (skills):\n\n1. navigate_to(location_name)\n   - Moves the robot to a labeled location (kitchen, desk, charger).\n2. find_object(object_name)\n   - Rotates head to look for an object. Returns x,y,z if found.\n3. pick_up(x, y, z)\n   - Attempts to grasp object at coordinates.\n4. speak(text)\n   - Says text aloud.\n\nUser: "I\'m thirsty, can you help?"\nContext: User is sitting on the couch. There is a kitchen nearby.\nOutput: A JSON list of actions.\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"2-react-reason--act",children:"2. ReAct: Reason + Act"}),"\n",(0,s.jsxs)(n.p,{children:["Simple prompting is often brittle. ",(0,s.jsx)(n.strong,{children:"ReAct"})," is a prompting strategy where the LLM intersperses thoughts with actions."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"User"}),': "Get me my water bottle."']}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"LLM Trace (ReAct)"}),":"]}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Thought"}),": User wants water. I need to find it first."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action"}),": ",(0,s.jsx)(n.code,{children:'navigate_to("kitchen")'})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Observation"}),": (Robot arrives at kitchen)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Thought"}),": I am in the kitchen. I need to see if the bottle is here."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action"}),": ",(0,s.jsx)(n.code,{children:'find_object("water bottle")'})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Observation"}),": Found at (1.2, 0.5, 0.8)."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Thought"}),": I see it. I can pick it up."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Action"}),": ",(0,s.jsx)(n.code,{children:"pick_up(1.2, 0.5, 0.8)"})]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:'This allows the robot to handle failures (e.g., if Observation was "Object not found", the Thought would change to "Maybe it\'s in the bedroom").'}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"3-implementing-the-planner-in-python",children:"3. Implementing the Planner in Python"}),"\n",(0,s.jsxs)(n.p,{children:["We use ",(0,s.jsx)(n.strong,{children:"LangChain"})," to manage this structured output."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:'from langchain.chat_models import ChatOpenAI\nfrom langchain.schema import SystemMessage, HumanMessage\nimport json\n\nllm = ChatOpenAI(model="gpt-4-turbo", temperature=0)\n\nsystem_prompt = """\nYou are a robot planner. Output strictly valid JSON.\nAvailable Actions: [navigate_to(loc), pick_up(obj), speak(text)].\n"""\n\ndef plan_task(user_command):\n    messages = [\n        SystemMessage(content=system_prompt),\n        HumanMessage(content=user_command)\n    ]\n    \n    response = llm.predict_messages(messages)\n    \n    try:\n        plan = json.loads(response.content)\n        return plan\n    except:\n        return []\n\n# Usage\ncmd = "Bring me a soda from the fridge"\nplan = plan_task(cmd)\n# Executor loop would iterate through \'plan\' and call ROS 2 services\n'})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"4-the-capstone-putting-it-all-together",children:"4. The Capstone: Putting it All Together"}),"\n",(0,s.jsx)(n.p,{children:"In the final project, you will combine:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Whisper"}),' (Hearing "Bring me a soda")']}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"LLM"})," (Planning the sequence)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Nav2"})," (Driving to the kitchen)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Isaac ROS"})," (Seeing the soda)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Controller"})," (Grabbing it)"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"This is the holy grail of Embodied AI."})]})}function d(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var o=t(6540);const s={},i=o.createContext(s);function r(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);