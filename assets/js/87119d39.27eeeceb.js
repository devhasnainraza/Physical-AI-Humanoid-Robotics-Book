"use strict";(globalThis.webpackChunkcortex_h1=globalThis.webpackChunkcortex_h1||[]).push([[9865],{8255:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>t,default:()=>h,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"module-3-ai-brain/sim-to-real","title":"3.6 Lab: Sim-to-Real (Domain Randomization)","description":"Robustifying policies by randomizing physics.","source":"@site/docs/module-3-ai-brain/06-sim-to-real.md","sourceDirName":"module-3-ai-brain","slug":"/module-3-ai-brain/sim-to-real","permalink":"/Cortex-H1/docs/module-3-ai-brain/sim-to-real","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-brain/06-sim-to-real.md","tags":[],"version":"current","sidebarPosition":6,"frontMatter":{"id":"sim-to-real","title":"3.6 Lab: Sim-to-Real (Domain Randomization)","sidebar_label":"3.6 Lab: Sim-to-Real","description":"Robustifying policies by randomizing physics."},"sidebar":"textbookSidebar","previous":{"title":"3.5 Model-Based RL","permalink":"/Cortex-H1/docs/module-3-ai-brain/model-based-rl"},"next":{"title":"4.1 Intro to VLA","permalink":"/Cortex-H1/docs/module-4-vla/intro-vla"}}');var s=i(4848),o=i(8453);const r={id:"sim-to-real",title:"3.6 Lab: Sim-to-Real (Domain Randomization)",sidebar_label:"3.6 Lab: Sim-to-Real",description:"Robustifying policies by randomizing physics."},t="3.6 Lab: Sim-to-Real (Domain Randomization)",l={},d=[{value:"\ud83c\udfaf Lab Objectives",id:"-lab-objectives",level:2},{value:"3.6.1 The Randomization Wrapper",id:"361-the-randomization-wrapper",level:2},{value:"3.6.2 Sim-to-Real Gap Checklist",id:"362-sim-to-real-gap-checklist",level:2},{value:"3.6.3 Quiz",id:"363-quiz",level:2}];function c(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"36-lab-sim-to-real-domain-randomization",children:"3.6 Lab: Sim-to-Real (Domain Randomization)"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:'"If you can walk on ice, you can walk on concrete."'})}),"\n",(0,s.jsx)(n.p,{children:"A policy trained in a perfect simulation will fail in reality. To fix this, we confuse the agent during training by constantly changing the physics."}),"\n",(0,s.jsx)(n.h2,{id:"-lab-objectives",children:"\ud83c\udfaf Lab Objectives"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Create a Gym Wrapper"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Randomize Mass and Length"}),"."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Train a Robust Policy"}),"."]}),"\n"]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"361-the-randomization-wrapper",children:"3.6.1 The Randomization Wrapper"}),"\n",(0,s.jsxs)(n.p,{children:["We will wrap ",(0,s.jsx)(n.code,{children:"Pendulum-v1"})," and change the pole mass every reset."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-python",children:"import gymnasium as gym\nimport numpy as np\n\nclass DomainRandomizationWrapper(gym.Wrapper):\n    def __init__(self, env):\n        super().__init__(env)\n        \n    def reset(self, **kwargs):\n        # 1. Randomize Mass (Default is 1.0)\n        new_mass = np.random.uniform(0.5, 2.0)\n        self.env.unwrapped.m = new_mass\n        \n        # 2. Randomize Length (Default is 1.0)\n        new_length = np.random.uniform(0.8, 1.2)\n        self.env.unwrapped.l = new_length\n        \n        return self.env.reset(**kwargs)\n\n# Usage\nenv = gym.make(\"Pendulum-v1\")\nenv = DomainRandomizationWrapper(env)\n\n# Now train PPO on this 'env'.\n# The agent will learn a policy that works for ALL masses between 0.5 and 2.0.\n"})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h2,{id:"362-sim-to-real-gap-checklist",children:"3.6.2 Sim-to-Real Gap Checklist"}),"\n",(0,s.jsx)(n.p,{children:"When deploying to a real robot, randomize:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Latency"}),": Add ",(0,s.jsx)(n.code,{children:"time.sleep(random)"})," in the step function."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Noise"}),": Add ",(0,s.jsx)(n.code,{children:"obs += np.random.normal()"})," to sensor data."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Friction"}),": (If using MuJoCo/PyBullet)."]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"363-quiz",children:"3.6.3 Quiz"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Why do we randomize mass?"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"a) We don't know the exact mass of the real robot (cables, tape)."}),"\n",(0,s.jsx)(n.li,{children:"b) To make the robot heavier."}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.em,{children:"Answer: a"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"What happens if we don't randomize?"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"a) The policy overfits to the simulation physics and fails in reality."}),"\n",(0,s.jsx)(n.li,{children:"b) Nothing."}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.em,{children:"Answer: a"})}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>r,x:()=>t});var a=i(6540);const s={},o=a.createContext(s);function r(e){const n=a.useContext(o);return a.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(o.Provider,{value:n},e.children)}}}]);