"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[602],{2460:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"module-2-digital-twin/sensor-plugins","title":"Simulating Sensors (LiDAR & Depth)","description":"A robot without sensors is blind. In Gazebo, we attach Plugins to the robot model to generate synthetic sensor data.","source":"@site/docs/module-2-digital-twin/03-sensor-plugins.md","sourceDirName":"module-2-digital-twin","slug":"/module-2-digital-twin/sensor-plugins","permalink":"/Cortex-H1/docs/module-2-digital-twin/sensor-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-2-digital-twin/03-sensor-plugins.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Simulating Sensors (LiDAR & Depth)"},"sidebar":"textbookSidebar","previous":{"title":"Building a Realistic World (SDF)","permalink":"/Cortex-H1/docs/module-2-digital-twin/gazebo-world"},"next":{"title":"Unity 3D Integration","permalink":"/Cortex-H1/docs/module-2-digital-twin/unity-integration"}}');var r=s(4848),a=s(8453);const t={sidebar_position:3,title:"Simulating Sensors (LiDAR & Depth)"},o="Simulating the Robot's Senses",l={},d=[{value:"1. The Sensor Plugin Architecture",id:"1-the-sensor-plugin-architecture",level:2},{value:"1.1 Adding a 2D LiDAR",id:"11-adding-a-2d-lidar",level:3},{value:"2. Simulating a Depth Camera (RealSense)",id:"2-simulating-a-depth-camera-realsense",level:2},{value:"2.1 The <code>ros_gz_bridge</code>",id:"21-the-ros_gz_bridge",level:3},{value:"3. Sensor Noise: The Mathematics",id:"3-sensor-noise-the-mathematics",level:2},{value:"3.1 Bias vs Noise",id:"31-bias-vs-noise",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"simulating-the-robots-senses",children:"Simulating the Robot's Senses"})}),"\n",(0,r.jsxs)(n.p,{children:["A robot without sensors is blind. In Gazebo, we attach ",(0,r.jsx)(n.strong,{children:"Plugins"})," to the robot model to generate synthetic sensor data."]}),"\n",(0,r.jsx)(n.h2,{id:"1-the-sensor-plugin-architecture",children:"1. The Sensor Plugin Architecture"}),"\n",(0,r.jsxs)(n.p,{children:["Sensors are defined inside a ",(0,r.jsx)(n.code,{children:"<link>"})," in your URDF/SDF."]}),"\n",(0,r.jsx)(n.h3,{id:"11-adding-a-2d-lidar",children:"1.1 Adding a 2D LiDAR"}),"\n",(0,r.jsx)(n.p,{children:"The standard for navigation is a 2D LiDAR (like the RPLidar). It scans a slice of the world."}),"\n",(0,r.jsxs)(n.p,{children:["Add this to your robot's URDF/SDF (inside the ",(0,r.jsx)(n.code,{children:"lidar_link"}),"):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="lidar" type="gpu_lidar">\n  <pose>0 0 0 0 0 0</pose>\n  <topic>/scan</topic>\n  <update_rate>10</update_rate> \x3c!-- 10 Hz --\x3e\n  <ray>\n    <scan>\n      <horizontal>\n        <samples>360</samples> \x3c!-- 1 degree resolution --\x3e\n        <resolution>1</resolution>\n        <min_angle>-3.14</min_angle>\n        <max_angle>3.14</max_angle>\n      </horizontal>\n    </scan>\n    <range>\n      <min>0.15</min>\n      <max>10.0</max>\n    </range>\n  </ray>\n  <always_on>true</always_on>\n  <visualize>true</visualize> \x3c!-- Draws blue rays in GUI --\x3e\n</sensor>\n'})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"2-simulating-a-depth-camera-realsense",children:"2. Simulating a Depth Camera (RealSense)"}),"\n",(0,r.jsx)(n.p,{children:"Humanoids need 3D vision. We simulate an RGB-D camera which produces two streams:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"RGB Image"}),": ",(0,r.jsx)(n.code,{children:"/camera/image_raw"})]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Depth Map"}),": ",(0,r.jsx)(n.code,{children:"/camera/depth/image_raw"})," (Distance to each pixel)"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<sensor name="camera" type="depth_camera">\n  <pose>0.1 0 0.5 0 0 0</pose>\n  <topic>/camera</topic>\n  <camera>\n    <horizontal_fov>1.047</horizontal_fov> \x3c!-- 60 degrees --\x3e\n    <image>\n      <width>640</width>\n      <height>480</height>\n      <format>R8G8B8</format>\n    </image>\n    <clip>\n      <near>0.1</near>\n      <far>10</far>\n    </clip>\n  </camera>\n  <always_on>1</always_on>\n  <update_rate>30</update_rate>\n  <visualize>true</visualize>\n</sensor>\n'})}),"\n",(0,r.jsxs)(n.h3,{id:"21-the-ros_gz_bridge",children:["2.1 The ",(0,r.jsx)(n.code,{children:"ros_gz_bridge"})]}),"\n",(0,r.jsx)(n.p,{children:"Gazebo produces messages in its own format (Ignition Transport). ROS 2 expects DDS messages. We need a bridge node to convert them."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Command:"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 run ros_gz_bridge parameter_bridge /scan@sensor_msgs/msg/LaserScan@gz.msgs.LaserScan\n"})}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"3-sensor-noise-the-mathematics",children:"3. Sensor Noise: The Mathematics"}),"\n",(0,r.jsxs)(n.p,{children:["Perfect sensors make for lazy AI. Real sensors are noisy.\nWe model noise using a ",(0,r.jsx)(n.strong,{children:"Gaussian Distribution"}),"."]}),"\n",(0,r.jsx)(n.p,{children:"For a true distance D_true, the sensor reports D_measured:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"D_measured = D_true + epsilon\nepsilon ~ Gaussian(mean, variance)\n"})}),"\n",(0,r.jsx)(n.p,{children:"Where:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"mean = 0.0 (Unbiased error)"}),"\n",(0,r.jsx)(n.li,{children:"$\\sigma$ (Standard Deviation) = 0.01 (1cm error)"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"In SDF:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:"<noise>\n  <type>gaussian</type>\n  <mean>0.0</mean>\n  <stddev>0.01</stddev> \n</noise>\n"})}),"\n",(0,r.jsx)(n.h3,{id:"31-bias-vs-noise",children:"3.1 Bias vs Noise"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Noise"}),": Random jitter (can be filtered by averaging)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Bias"}),": Constant offset (e.g., sensor always reads +5cm)."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Drift"}),": Bias that changes over time (IMU drift)."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Simulating ",(0,r.jsx)(n.strong,{children:"Drift"})," is crucial for testing VSLAM loop closure capabilities."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>o});var i=s(6540);const r={},a=i.createContext(r);function t(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:t(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);