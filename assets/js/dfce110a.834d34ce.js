"use strict";(globalThis.webpackChunktemp_docusaurus=globalThis.webpackChunktemp_docusaurus||[]).push([[4958],{8169:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});const i=JSON.parse('{"id":"module-3-ai-brain/visual-slam","title":"Visual SLAM","description":"1. The Localization Problem","source":"@site/docs/module-3-ai-brain/03-visual-slam.md","sourceDirName":"module-3-ai-brain","slug":"/module-3-ai-brain/visual-slam","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-brain/visual-slam","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-ai-brain/03-visual-slam.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Visual SLAM"},"sidebar":"textbookSidebar","previous":{"title":"Nav2 Architecture","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-3-ai-brain/navigation-stack"},"next":{"title":"Vision-Language-Action (VLA)","permalink":"/Physical-AI-Humanoid-Robotics-Book/docs/module-4-vla/intro"}}');var t=s(4848),a=s(8453);const l={sidebar_position:3,title:"Visual SLAM"},r="Visual SLAM: Seeing and Mapping",o={},c=[{value:"1. The Localization Problem",id:"1-the-localization-problem",level:2},{value:"2. Visual vs LiDAR SLAM",id:"2-visual-vs-lidar-slam",level:2},{value:"3. How VSLAM Works (Simplified)",id:"3-how-vslam-works-simplified",level:2},{value:"4. Using <code>isaac_ros_visual_slam</code>",id:"4-using-isaac_ros_visual_slam",level:2},{value:"4.1 Launching VSLAM",id:"41-launching-vslam",level:3}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"visual-slam-seeing-and-mapping",children:"Visual SLAM: Seeing and Mapping"})}),"\n",(0,t.jsx)(n.h2,{id:"1-the-localization-problem",children:"1. The Localization Problem"}),"\n",(0,t.jsx)(n.p,{children:"Before a robot can navigate, it must answer two questions:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Mapping"}),": What does the world look like?"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Localization"}),": Where am I in that world?"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"SLAM (Simultaneous Localization and Mapping)"})," solves both at once."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"2-visual-vs-lidar-slam",children:"2. Visual vs LiDAR SLAM"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{style:{textAlign:"left"},children:"Feature"}),(0,t.jsx)(n.th,{style:{textAlign:"left"},children:"LiDAR SLAM (e.g., Slam Toolbox)"}),(0,t.jsx)(n.th,{style:{textAlign:"left"},children:"Visual SLAM (e.g., ORB-SLAM3)"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"left"},children:(0,t.jsx)(n.strong,{children:"Input"})}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Laser Scan (2D/3D points)"}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Camera Images (Pixels)"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"left"},children:(0,t.jsx)(n.strong,{children:"Features"})}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Corners, Walls"}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Textures, Edges, Objects"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"left"},children:(0,t.jsx)(n.strong,{children:"Failure Mode"})}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Long corridors (geometric similarity)"}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Low light, motion blur, featureless white walls"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"left"},children:(0,t.jsx)(n.strong,{children:"Cost"})}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"High (LiDARs are expensive)"}),(0,t.jsx)(n.td,{style:{textAlign:"left"},children:"Low (Cameras are cheap)"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:["For humanoids, we prefer ",(0,t.jsx)(n.strong,{children:"Visual SLAM"})," because cameras are lightweight and we need them for object recognition anyway."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"3-how-vslam-works-simplified",children:"3. How VSLAM Works (Simplified)"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Feature Extraction"}),': The algorithm looks for "interesting points" (corners, high contrast spots) in the image.']}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Feature Matching"}),": It finds the same points in the ",(0,t.jsx)(n.em,{children:"next"})," frame."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Motion Estimation"}),": based on how the points moved, it calculates how the camera must have moved.","\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.em,{children:"Example"}),": If all points moved Left, the Camera moved Right."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Loop Closure"}),': The "Aha!" moment. "I recognize this room! I was here 5 minutes ago!" The algorithm snaps the current map to align with the old map, fixing drift errors.']}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.h2,{id:"4-using-isaac_ros_visual_slam",children:["4. Using ",(0,t.jsx)(n.code,{children:"isaac_ros_visual_slam"})]}),"\n",(0,t.jsx)(n.p,{children:"NVIDIA provides a highly optimized VSLAM package for the Jetson."}),"\n",(0,t.jsx)(n.h3,{id:"41-launching-vslam",children:"4.1 Launching VSLAM"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from launch import LaunchDescription\nfrom launch_ros.actions import ComposableNodeContainer\nfrom launch_ros.descriptions import ComposableNode\n\ndef generate_launch_description():\n    visual_slam_node = ComposableNode(\n        name='visual_slam_node',\n        package='isaac_ros_visual_slam',\n        plugin='nvidia::isaac_ros::visual_slam::VisualSlamNode',\n        parameters=[{\n            'enable_imu_fusion': True, # Use gyroscope for better stability\n            'enable_rectified_pose': True\n        }],\n        remappings=[\n            ('stereo_camera/left/image_rect', '/camera/left/image_rect'),\n            ('stereo_camera/right/image_rect', '/camera/right/image_rect'),\n            ('visual_slam/imu', '/camera/imu')\n        ]\n    )\n\n    return LaunchDescription([\n        ComposableNodeContainer(\n            name='visual_slam_container',\n            namespace='',\n            package='rclcpp_components',\n            executable='component_container',\n            composable_node_descriptions=[visual_slam_node],\n            output='screen'\n        )\n    ])\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Key Requirement"}),": VSLAM needs a ",(0,t.jsx)(n.strong,{children:"Stereo Camera"})," (Left + Right) or a ",(0,t.jsx)(n.strong,{children:"Depth Camera"})," to understand scale. With a single Mono camera, you can map the world, but you won't know if a hallway is 1 meter long or 100 meters long (scale ambiguity)."]})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>r});var i=s(6540);const t={},a=i.createContext(t);function l(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(a.Provider,{value:n},e.children)}}}]);